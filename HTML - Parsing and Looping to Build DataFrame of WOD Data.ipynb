{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc315cb",
   "metadata": {},
   "source": [
    "# This workbook uses for loop to iterate over SQL generated list of URLs based on URL pattern convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d1568",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61aa81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                #Requests is an elegant and simple HTTP library for Python, built for human beings.\n",
    "from bs4 import BeautifulSoup  #Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
    "import pandas as pd            #pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n",
    "import numpy as np             #NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import os                      #This module provides a portable way of using operating system dependent functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ecb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad727c98",
   "metadata": {},
   "source": [
    "## File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_file = r'C:\\Users\\halin\\OneDrive\\Documents\\Data_Coding_Reporting\\Inguz\\URLs_1.1.20_to_12.31.22.xlsx'\n",
    "df_url = pd.read_excel(url_file,engine='openpyxl')\n",
    "url_list = df_url['Full URL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b3c1e",
   "metadata": {},
   "source": [
    "## HTML Parsing, Looping, and Appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6041ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []                                         #create list to append each dataframe interation to\n",
    "\n",
    "for url in url_list[:798]:                          #slicing takes 0 to 2 (798 will return data through 3.9.22)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find('div',id='left-area')\n",
    "    date_results = soup.find(class_ = 'entry-title')\n",
    "    workout_elements = results.find_all('p',class_ = lambda x: x != 'wp-caption-text' and x != 'post-meta', style=False)\n",
    "    #print(results.prettify())\n",
    "    \n",
    "    d = []\n",
    "\n",
    "    for workout_element in workout_elements:\n",
    "        d.append(\n",
    "            {\n",
    "                workout_element.text.strip()\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(d)\n",
    "    df.columns=['Data']\n",
    "    df['Data'] = df['Data'].str.split('\\n')\n",
    "    df2= df.explode('Data',ignore_index=True)\n",
    "    if date_results is not None:\n",
    "        date_text = date_results.text\n",
    "    else: \n",
    "        date_text = None \n",
    "    df2['Date'] = date_text\n",
    "    df2['Row Type'] = np.nan\n",
    "    df2.loc[df2['Data'].str.contains('STRENGTH', case=False)==True,'Row Type'] = 'STRENGTH'\n",
    "    df2.loc[df2['Data'].str.contains('WOD', case=False)==True,'Row Type'] = 'WOD'\n",
    "    df2.loc[df2['Data'].str.contains('MOVE 45', case=False)==True,'Row Type'] = 'Move 45'\n",
    "    df2.loc[df2['Data'].str.contains('ACCESSORY WORK', case=False)==True,'Row Type'] = 'ACCESSORY WORK'\n",
    "    df2.loc[df2['Data'].str.contains('After Party', case=False)==True,'Row Type'] = 'After Party'\n",
    "    df2.loc[df2['Data'].str.contains('Olympic Lifting', case=False)==True,'Row Type'] = 'Olympic Lifting'\n",
    "    df2['Row Type']=df2['Row Type'].ffill()\n",
    "    df_wod = df2[df2['Row Type']=='WOD']\n",
    "    data.append(df_wod)\n",
    "    \n",
    "appended_data=pd.concat(data)\n",
    "appended_data.to_csv('wod_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wod #validating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e69b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data #validating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fbddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
